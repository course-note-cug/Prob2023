\section{条件数学期望}



    \begin{definition}
        设随机变量$X$在$y=y_i$的条件下的条件分布列为
        $$
        p_{i|j}=P(X=x_i | Y=y_j),
        $$
        若级数$\sum_i x_i p_{i|j}$绝对收敛, 那么称此级数$Y=Y_i$条件下$X$的条件数学期望, 记为$\Ep{X|Y=y_i}$.
    \end{definition}

    正如条件概率也是概率, 条件数学期望也是数学期望. 自然, 它就满足数学期望对应的性质. 

    \begin{example}
        有一根长度为$l$的棍子, 在$(0,l)$内均匀地取一点$X$折断. 再次在$(0,a)$选一点$Y$折断. 求$Y$的期望. 
    \end{example}

    \begin{solution}
        假设$Y$是一个具体值的情形. $\Ep{X \mid Y=y}=\frac{y}{2}$是一个数字. 但是实验之前, 这个值是随机的. 我们干脆把它写作$\Ep{X|Y}$作为一个随机变量. 其中, 记作$\Ep{X|Y}=Y/2$.
    \end{solution}



    下面来看有时候如何方便地计算期望. 我们可以把样本空间构成一组不相交的集合$A_1, A_2, \cdots, A_n$, 因此可以在每个小块上面计算期望值. 也就是: $$
    \Ep{X}=P\left(A_1\right) \Ep{X \mid A_1}+\cdots+P\left(A_n\right) \Ep{X \mid A_n} .
    $$
    这个可以使用全概率公式, 两边乘上其对应的系数得到. 这就是\textbf{全期望公式}. 


    有了这样的记号, 我们给出指数分布的期望的又一说明: 
    \begin{example}
        
    我们把原来的事件划分为不相交的两类. 
    $$
    \begin{aligned}
    & A_1:\{x=1\}, \quad A_2:\{x>1\} . \\
    & \Ep{X}=P(X=1) \Ep{X \mid x=1}+P(X>1) \Ep{X \mid x>1} .
    \end{aligned}
    $$
    那么计算它就得到了: 
    $$
\begin{aligned}
\Ep{X} & =P(X=1) E[X \mid x=1]+P(X>1) E[X \mid x>1] . \\
& =p \cdot 1+(1-p)\boxed{~~?~~}
\end{aligned}
$$
我们关注$E[X \mid x>1]$的情形, $$
\begin{aligned}
E[X \mid x-1>0] & =E[X-1 \mid x-1>0]+1 \\
& =\Ep{X}+1
\end{aligned}
$$
由于指数分布的无记忆性, 上面的式子就是$\Ep{X}+1$. 

上面的式子经过整理得到$\Ep{X}=p \cdot 1+(1-p)(\Ep{X}+1)$. 我们由此解答出来$\Ep{X}$, 因此就得到期望值为$1/p$. 

    \end{example}

    \subsection{迭代的期望}

    我们接下来考虑期望的迭代公式, 也就是$\mathbb{E}[\mathbb{E}[X \mid Y]]$. 这个符号看上去很难懂. 我们先从简单来看这个公式: 
    \begin{itemize}
        \item $\mathbb{E}[X \mid Y=y]$表示当随机变量$Y$取值$y$的时候, 随机变量$X$的期望. 
        \item 考虑所有可能的$Y$, 其构成的一组期望就是$\mathbb{E}_y[X \mid Y=y], \forall y$. 
        \item 这一组期望, 是一个关于$Y$的随机变量.为了简便,我们把这样的一组简写为$\mathbb{E}[X \mid Y]$.
        \item 对于这样的一个随机变量, 自然可以求它的期望. 
    \end{itemize}

    实际上, 这个公式有一个更简洁的表示. 我们按照定义展开: 
    $$\begin{aligned} \text{左手边} & =\int_{-\infty}^{+\infty}\left(\int_{-\infty}^{+\infty} \frac{f_{x, Y}(x, y)}{f_Y(y)} d x\right) f_Y(y) d y \\ & =\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} x f_{x, Y}(x, y) d x d y . \\ & =\int_{-\infty}^{+\infty} x f_x(x) d x=\mathbb{E}[x]=\text{右手边}\end{aligned}$$

    这个公式有一个名字, 叫做``迭代期望定律(Law of iterated expectations)''. 

    \begin{theorem}
        迭代的期望公式:$$
\mathbb{E}[{\mathbb{E}}[X \mid Y]]=\mathbb{E}[X]
$$
    \end{theorem}

    \subsection{练习: 仅仅依赖上一个状态的Markov链}

        \begin{wrapfigure}{l}{0.4\textwidth}
        \begin{center}
            \input{fig/ch4/markov-eg.tex}
        \end{center}
        \caption{班主任探访的规律}
        \label{fig:meeting-supervisor-pattern}
    \end{wrapfigure}
    \paragraph{第一幕 Markov链带来的稳定分布} 有三个喜欢自学的聪明学生A,B,C. 他们整天喜欢在宿舍学习. 这自然会使他们的班主任不开心. 这就会导致班主任每天就去他们的寝室去观察, 以确保他们确实在学习. 
    
    由于他们足够聪明, 经过一段时间的观察, 他们认为班主任会按照如\cref{fig:meeting-supervisor-pattern}这样的的规律来``探访''他们.  如果我们只看$A$同学和黑色的箭头, 其意义如下: 

    若今天班主任找$A$同学, 那么明天: 
    \begin{itemize}
        \item 0.6的概率找$B$;
        \item 0.2的概率找$C$;
        \item 0.2的概率找$A$.
    \end{itemize}

    这里一个关键的假设是: 未来的状态仅仅取决于\emph{当前状态}. 也就是$P(X_{n+1}=x|X_n=x_n)$.
    
    在这个假设下, 如果我们已知班主任老师第一天找$B$, 第二天找$A$, 那么请问, 第三天找$C$的概率为多大? 按照我们刚刚的假设, 第三天找谁只与第二天有关. 因此第二天找了$A$, 自然第三天找$C$的概率为0.2. 

    自然, 日子一天天的过去, 他们想知道从长期来看, 班主任来``探访''他们的概率是多少. 比如, 他们记录了10天以内班主任的行踪轨迹: 
    $$
    A \to B \to A\to C \to A \to C\to C\to C\to A\to B.
    $$

    在这10天里面, $P(A\text{被找到}), P(B\text{被找到}),P(C\text{被找到})$的概率分别为4/10, 2/10, 4/10. 
    
    