\section{大数定律}
\paragraph{大数定律及其重要推论}

我们先来看构建概率极限定理的一些工具.

\begin{theorem}[Chebyshev\newword{大数律}{law of big numbers}] 
    设 $X_1, X_2, \cdots$ 是相互独立的随机变量序列, $\mathbb{E}\left(X_i\right)=\mu_i, \operatorname{var}\left(X_i\right)=\sigma_i^2(i \geq 1)$ 且 $\left\{\sigma_i^2, i \geq 1\right\}$ 有界, 设 $S_n=\sum_{i=1}^n X_i$ $(n \geq 1)$, 则
$$
\frac{S_n-\mathbb{E}\left(S_n\right)}{n} \stackrel{P}{\longrightarrow} 0 \quad(n \rightarrow \infty) .
$$
\end{theorem}

\begin{proof}
    设 $\sigma_i^2 \leq M($ 一切 $i \geq 1$ ). 利用Chebyshev不等式知
$$
\begin{aligned}
P\left(\left|\frac{S_n-\mathbb{E}\left(S_n\right)}{n}\right| \geq \varepsilon\right) & =P\left(\left|S_n-\mathbb{E}\left(S_n\right)\right| \geq n \varepsilon\right) \\
& \leq \frac{1}{n^2 \varepsilon^2} \operatorname{Var}\left(S_n\right) .
\end{aligned}
$$

由于 $X_1, \cdots, X_n$ 两两不相关, $\operatorname{Var}\left(S_n\right)=\sum_{i=1}^n \operatorname{Var}\left(X_i\right) \leq n M$. 于是
$$
P\left(\left|\frac{S_n-\mathbb{E}\left(S_n\right)}{n}\right| \geq \varepsilon\right) \leq \frac{M}{n \varepsilon^2} \quad(\text { 一切 } \varepsilon>0) .
$$
由此得证. 

\end{proof}

我们就立刻可以得到这样的一个有用的推论: 

\begin{corollary}
    设 $X_1, X_2, \cdots$ 是相互\newword{独立同分布}{independent identical distribution, i.i.d.}的随机变量序列, $\mu=\mathbb{E}\left(X_1\right)$ 和 $\sigma^2=\operatorname{var}\left(X_1\right)$ 都存在, $S_n=\sum_{i=1}^n X_i(n \geq 1)$, 则
    $$
    \frac{S_n}{n} \stackrel{P}{\longrightarrow} \mu \quad(n \rightarrow \infty) .
    $$
\end{corollary}



\begin{corollary}
    设单次试验中事件 $A$ 发生的概率是 $p$, 在 $n$ 次独立试验 $(n \geq 2)$ 中 $A$ 发生了 $\nu_n$ 次, 则
$$
\frac{\nu_n}{n} \stackrel{P}{\longrightarrow} p(n \rightarrow \infty) .
$$
\end{corollary}

\begin{proof}令
$$
X_i= \begin{cases}1, & \text { 第 } i \text { 次试验中 } A \text { 发生, } \\ 0, & \text { 第 } i \text { 次试验中 } A \text { 不发生 }\end{cases}
$$
$(i=1,2, \cdots)$, 则 $\frac{\nu_n}{n}=\frac{1}{n} \sum_{i=1}^n X_i$. 由于 $X_1, X_2, \cdots$ 是相互独立同分布的随机变量序列, $\mathbb{E}\left(X_i\right)=p, \operatorname{var}\left(X_i\right)=p(1-p)(i \geq 1)$. 因此成立.
\end{proof}

上面的两个推论, 尤其是第一个推论是我们最常用到的大数律, 其中方差存在的条件可以去掉, 而且可以证明更强的结论, 但证明较复杂, 我们在这里就不证明了. 那么如果对于数学期望不存在的时候, 是否存在常数$a$使得$\sum_{i=1}^n X_i \stackrel{P}{\longrightarrow} a \quad(n \rightarrow \infty)$? 我们看一个例子: 

\begin{example}
    设 $X_1, X_2, \cdots$ 是相互独立同分布的随机变量序列, 共同分布是Cauchy分布, 即密度函数是
$$
p(x)=\frac{1}{\pi\left(1+x^2\right)} .
$$

记 $S_n=\sum_{i=1}^n X_i(n \geq 1)$. 可以证明对任何 $n \geq 1, \frac{1}{n} S_n$ 与 $X_1$ 有相同的分布函数. 因此对任何实数 $a$ 和 $\varepsilon>0$,
$$
P\left(\left|\frac{S_n}{n}-a\right| \geq \varepsilon\right) \equiv P\left(\left|X_1-a\right| \geq \varepsilon\right)>0 .
$$

故 $\frac{S_n}{n}$ 不能以概率收敛于 $a$.
\end{example}

那么什么时候类似的定律成立? 我们给出如下事实: 

\begin{theorem}
     [Cantelli 强大数律] 设 $X_1, X_2, \cdots$ 是相互独立的随机变量序列, $\mathbb{E}\left(X_i\right)=\mu_i, \mathbb{E}\left(X_i-\mu_i\right)^4 \leq M$ (一切 $i \geq 1 ; M$ 是一个常数), $S_n=$ $\sum_{i=1}^n X_i(n \geq 1)$, 则当 $n \rightarrow \infty$ 时,
$$
\frac{S_n-\mathbb{E}\left(S_n\right)}{n} \stackrel{\text { a.s. }}{\longrightarrow} 0 .
$$
\end{theorem}

其证明较为复杂. 

{
    \small
    先证明一个引理: 
         $X_1, \cdots, X_n$ 相互独立 $(n \geq 2)$, 且 $\mathbb{E}\left(X_i\right)=0, \mathbb{E}\left(X_i^4\right) \leq$ $M(i=1, \cdots, n)$, 则
$$
\mathbb{E}\left(\sum_{i=1}^n X_i\right)^4 \leq 3 n^2 M
$$
\begin{proof}
     用数学归纳法. 显然 上述 式对 $n=1$ 成立. 设 $n=k$ 时 (2.5)式成立, 则
$$
\begin{aligned}
\left(\sum_{i=1}^{k+1} X_i\right)^4= & \left(\sum_{i=1}^k X_i+X_{k+1}\right)^4 \\
= & \left(\sum_{i=1}^k X_i\right)^4+4\left(\sum_{i=1}^k X_i\right)^3 X_{k+1}+6\left(\sum_{i=1}^k X_i\right)^2 X_{k+1}^2 \\
& +4\left(\sum_{i=1}^k X_i\right) X_{k+1}^3+X_{k+1}^4
\end{aligned}
$$

于是
$$
\begin{aligned}
& \mathbb{E}\left(\sum_{i=1}^{k+1} X_i\right)^4=\mathbb{E}\left(\sum_{i=1}^k X_i\right)^4+4 \mathbb{E}\left(\sum_{i=1}^k X_i\right)^3 \cdot \mathbb{E}\left(X_{k+1}\right) \\
& \quad+6 \mathbb{E}\left(\sum_{i=1}^k X_i\right)^2 \cdot \mathbb{E}\left(X_{k+1}^2\right)+4 \mathbb{E}\left(\sum_{i=1}^k X_i\right) \cdot \mathbb{E}\left(X_{k+1}^3\right)+\mathbb{E}\left(X_{k+1}^4\right) . \\
& \text { 由于 } \mathbb{E}\left(X_i^2\right) \leq\left(\mathbb{E}\left(X_i^4\right)\right)^{\frac{1}{2}}, \mathbb{E}\left(X_i\right)=0 \text { 且 } \mathbb{E}\left(\sum_{i=1}^k X_i\right)^2=\mathbb{E}\left(X_1^2\right)+\cdots+
\end{aligned}
$$
$\mathbb{E}\left(X_k^2\right) \leq k \sqrt{M}$, 故
$$
\begin{aligned}
\mathbb{E}\left(\sum_{i=1}^{k+1} X_i\right)^4 & \leq 3 k^2 M+0+6 k M+0+M \\
& \leq 3(k+1)^2 M
\end{aligned}
$$
\end{proof}

下面开始证明定理: 
\begin{proof}
    注意定理中的条件 $X_i=X_i(\omega)(i \geq 1), S_n$
$$
\begin{aligned}
& S_n(\omega)=\sum_{i=1}^n X_i(\omega) \text {. 令 } \\
& \qquad D=\left\{\omega_{:} \sum_{n=1}^{\infty}\left(\frac{S_n(\omega)-\mathbb{E}\left(S_n\right)}{n}\right)^4 \text { 发散 }\right\} .
\end{aligned}
$$

我们来证明 $P(D)=0$.
任给定 $A>0$, 令
$$
D_N=\left\{\omega: \sum_{n=1}^N\left(\frac{S_n(\omega)-\mathbb{E}\left(S_n\right)}{n}\right)^4>A\right\} \quad(N \geq 1),
$$

则 $D \subset \bigcup_{N=1}^{\infty} D_N$, 由此有
$$
P(D) \leq P\left(\bigcup_{N=1}^{\infty} D_N\right)=\lim _{N \rightarrow \infty} P\left(D_N\right) .
$$

另一方面, 
$$
A I_{D_N}(\omega) \leq \sum_{n=1}^N\left(\frac{S_n(\omega)-\mathbb{E}\left(S_n\right)}{n}\right)^4
$$

于是
$$
\begin{aligned}
\mathbb{E}\left(A I_{D_N}(\omega)\right) & \leq \mathbb{E}\left(\sum_{n=1}^N\left(\frac{S_n(\omega)-\mathbb{E}\left(S_n\right)}{n}\right)^4\right) \\
& =\sum_{n=1}^N \mathbb{E}\left(\frac{S_n(\omega)-\mathbb{E}\left(S_n\right)}{n}\right)^4 \\
& \leq \sum_{n=1}^N \frac{1}{n^4} 3 n^2 M \quad\text { (上述引理) } \\
& \leq 3 M \sum_{n=1}^{\infty} \frac{1}{n^2} .
\end{aligned}
$$
由于 $\mathbb{E}\left(A I_{D_N}(\omega)\right)=A \mathbb{E}\left(I_{D_N}(\omega)\right)=A P\left(D_N\right)$, 因此
$$
P\left(D_N\right) \leq \frac{3 M}{A} \sum_{n=1}^{\infty} \frac{1}{n^2} .
$$

令 $N \rightarrow \infty$, 从 (2.6)式得 $P(D) \leq \frac{3 M}{A} \sum_{n=1}^{\infty} \frac{1}{n^2}$. 令 $A \rightarrow \infty$, 知 $P(D)=0$, 故
$P\left(D^c\right)=1$. 当 $\omega \in D^c$ 时级数 $\sum_{n=1}^{\infty}\left(\frac{S_n(\omega)-\mathbb{E}\left(S_n\right)}{n}\right)^4$ 收敛, 从而
$$
\lim _{n \rightarrow \infty} \frac{S_n(\omega)-\mathbb{E}\left(S_n\right)}{n}=0 .
$$

这表明定理式成立.
\end{proof}
}

这就给了我们一个很直接的推论: 
\begin{corollary}
    设 $X_1, X_2, \cdots$ 是相互独立同分布的随机变量序列, $\mu=\mathbb{E}\left(X_1\right)$ 和 $\mathbb{E}\left(X_1^4\right)$ 存在, $S_n=\sum_{i=1}^n X_i(n \geq 1)$, 则当 $n \rightarrow \infty$ 时,
$$
\frac{S_n}{n} \stackrel{\text { a.s. }}{\longrightarrow} \mu .
$$
\end{corollary}

这个推论是上面的定理的直接结果. 它就回答了我们什么情况下我们可以使用大数定律. 

\paragraph{大数定律的应用}

大数定律是很多统计方法的理论依据. 例如, 为了估计随机变量 $X$ 的期望,若 $X_1, X_2, \cdots, X_n$ 是 $X$ 的 $n$ 次观测值, 人们常用平均值 $\bar{X}=\frac{1}{n} \sum_{i=1}^n X_i$ 作为 $\mathbb{E}(X)$ 的估计量 (近似值).由于强大数律: 当 $n \rightarrow \infty$ 时, $\frac{1}{n} \sum_{i=1}^n X_i \stackrel{\text { a.s. }}{\longrightarrow} \mathbb{E}(X)$, 故 $n$ 较大时用 $X$ 估计 $\mathbb{E}(X)$ 是合理的. 对于 $X$ 的方差, 人们常用 $\frac{1}{n} \sum_{i=1}^n\left(X_i-\bar{X}\right)^2$ 作为 $\operatorname{var}(X)$的估计量. 利用强大数律知
$$
\begin{gathered}
\lim _{n \rightarrow \infty} \frac{1}{n} \sum_{i=1}^n\left(X_i-\bar{X}\right)^2=\lim _{n \rightarrow \infty}\left\{\frac{1}{n} \sum_{i=1}^n X_i^2-\left(\frac{\sum_{i=1}^n X_i}{n}\right)^2\right\} \\
\left.=\mathbb{E}\left(X_1^2\right)-\left(\mathbb{E}\left(X_1\right)\right)^2=\operatorname{var}(X) \quad \text { (a.s. }\right) .
\end{gathered}
$$

这表明, 当 $n$ 较大时用 $\frac{1}{n} \sum_{i=1}^n\left(X_i-\bar{X}\right)^2$ 估计 $X$ 的方差是合理的.

除此之外, 大数定律同样告诉了我们使用计算机模拟的可行性. 为了计算随机变量 $X$ 的期望 $\mathbb{E}(X)$, 若能够产生与 $X$ 有相同概率分布的相互独立的随机变量序列 $X_1, X_2, \cdots$, 则据强大数律, $X=\frac{1}{n} \sum_{i=1}^n X_i$就是 $\mathbb{E}(X)$ 的近似值 (当 $n$ 很大时).

怎样得到与 $X$ 有相同分布的相互独立的随机变量序列 $X_1, X_2, \cdots$呢? 设 $X$ 的分布函数是 $F(x), U_1, U_2, \cdots$ 是服从 $(0,1)$ 上均匀分布的相互独立的随机变量序列. 令 $X_i=F^{-1}\left(U_i\right)(i \geq 1)$, 这里
$$
F^{-1}(u)=\min \{x, F(x) \geq u\} \quad(0<u<1)
$$

是随机变量 $X$ 的 $u$ 中位数. 并且 $X_1, X_2, \cdots$ 是相互独立同分布的随机变量序列, 联合分布恰好是 $F(x)$.

\begin{example}
    我们在计算积分 $I=\int_a^b f(x) \mathrm{d} x$的时候, 可以使用随机模拟法进行计算. 不失一般性, 假定被积函数是非负的. 对于一般情形, 设 $f(x)$ 有下界 $A$. 令 $f^*(x)=f(x)-A$, 则 $f^*(x) \geq 0$ 且
    $$
    \int_a^b f(x) \mathrm{d} x=\int_a^b f^*(x) \mathrm{d} x+A(b-a),
    $$
    
    故只需考虑非负函数的积分. 设 $u_1, u_2, \cdots$ 是服从 $(0,1)$ 上均匀分布的相互独立的随机变量序列, 令 $\xi_i=a+(b-a) u_i$, 则 $\xi_i$ 服从 $(a, b)$ 上的均匀分布. 依强大数律, 当 $n \rightarrow \infty$ 时,
    $$
    \frac{1}{n} \sum_{i=1}^n f\left(\xi_i\right) \stackrel{\text { a.s. }}{\longrightarrow} \mathbb{E} f\left(\xi_1\right) .
    $$
    
    由于 $\mathbb{E} f\left(\xi_1\right)=\int_a^b f(x) \frac{1}{b-a} \mathrm{~d} x$, 故 $n$ 很大时,
    $$
    \int_a^b f(x) \mathrm{d} x \approx(b-a) \frac{1}{n} \sum_{i=1}^n f\left(\xi_i\right) .
    $$
    
    由此可见, 只要得到服从 $(0,1)$ 上均匀分布的随机数 $u_1, \cdots, u_n$, 就可得到 $\int_a^b f(x) \mathrm{d} x$ 的近似值.
    并且, 这个方法可推广用于计算高维的数值积分
    $$
    \int \cdots \int_D f\left(x_1, \cdots, x_m\right) \mathrm{d} x_1 \cdots \mathrm{d} x_m,
    $$
    具体叙述从略.
\end{example}