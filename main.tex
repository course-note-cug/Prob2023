% !TEX root = main.tex
\input{include.tex}
\usepackage{ctex}
\usepackage{pifont}
\usepackage{cleveref}
\usepackage{pstricks}
\usepackage{pgfplots}
% \usepackage[utf8]{inputenc}
\input{crefchn}
\begin{document}

\input{titlepage.tex}

我们假定读者已经学习或正在学习《高等数学》、《离散数学》、《算法导论》的课程. 其中, 学习并熟练理解高等数学中的概念是至关重要的. 

\part{概率论中基本的概念}
\input{text/ch1/1-intro.tex}
\input{text/ch1/2-prob-evt.tex}
\begin{shaded}
    \input{aside/2star-counting-techique.tex}
\end{shaded}
\input{text/ch1/3-cond-prob.tex}
\input{text/ch1/4-indep.tex}
\begin{shaded}
    \input{aside/1-dependent-formal.tex}
\end{shaded}

\part{一维随机变量}
\input{text/ch2/1-rv.tex}
\input{text/ch2/2-discrete-rv.tex}
\input{text/ch2/3-cont-rv.tex}
\input{text/ch2/4-derived.tex}

\part{多维随机变量及其分布}
\input{text/ch3/1-2drv.tex}
\input{text/ch3/2-margin.tex}
\input{text/ch3/3-dependent.tex}
\input{text/ch3/4-rv-func.tex}

\part{随机变量的数字特征}
\input{text/ch4/1-expectation.tex}
\input{text/ch4/2-cond-expectation.tex}
\input{text/ch4/3-expectation-ineq.tex}
\input{exercise/ch4/exp.tex}
\input{text/ch4/4-vari-intro.tex}
\input{text/ch4/5-cov-mom.tex}
\input{text/ch4/6-median-mean.tex}

\part{概率的极限定理}
\input{text/ch5/1-cov-seqs.tex}
\input{text/ch5/2-lln.tex}

\section{Chernoff界和Hoeffding界}

我们导出两个比较有用的界限. 这两个界限可以告诉我们关于分布的尾部其实是呈指数式衰减的. 这些界限是通过将Markov不等式应用于随机变量的矩生成函数而得出的. 在讨论之前, 我们先介绍重要的一个重要的概念, 也就是矩的生成函数. 

\subsection{矩的生成函数}

\begin{definition}
    对于一个随机变量 $X$, 它的矩生成函数为$$M_X(t)=\mathbf{E}\left[\mathrm{e}^{t X}\right].$$
\end{definition}

我们主要考察它在0附近的存在性和性质. 这样的一个函数$M_X(t)$实际上捕捉了$X$的所有矩. 我们马上会看到这一点.

\begin{theorem}
    假设随机变量 $X$ 的矩生成函数为 $M_X(t)$. 
在可以交换期望值和微分操作的前提下, 对于所有 $n > 1$, 我们可以得到
$$E[X^n] = M_X^{(n)}(0),$$这里的 $M_X^{(n)}(0)$ 表示 $M_X(t)$ 在 $t = 0$ 处的第 $n$ 阶导数的值. 

\end{theorem}
\begin{proof}
    假设我们可以交换积分和期望的次序, 那么有$M_X^{(n)}(t)=\mathbf{E}\left[X^n \mathrm{e}^{t X}\right]$. 带入$t=0$, 得到$M_X^{(n)}(0)=\mathbf{E}\left[X^n\right]$. 
\end{proof}

\begin{example}
    下面我们来看一个例子, 矩的生成函数是如何编码一个随机变量的所有的矩的. 对于一个参数为$p$的几何分布($\operatorname{P}(X=n)=(1-p)^{n-1} p$), 那么对于$t<-\ln(1-p)$, 有
    $$\begin{aligned} M_X(t) & =\mathbf{E}\left[\mathrm{e}^{t X}\right] \\ & =\sum_{k=1}^{\infty}(1-p)^{k-1} p \mathrm{e}^{t k} \\ & =\frac{p}{1-p} \sum_{k=1}^{\infty}(1-p)^k \mathrm{e}^{t k} \\ & =\frac{p}{1-p}\left(\left(1-(1-p) \mathrm{e}^t\right)^{-1}-1\right)\end{aligned}$$

    也就是
    $$\begin{aligned} & M_X^{(1)}(t)=p\left(1-(1-p) \mathrm{e}^t\right)^{-2} \mathrm{e}^t \quad \text { 并且 } \\ & M_X^{(2)}(t)=2 p(1-p)\left(1-(1-p) \mathrm{e}^t\right)^{-3} \mathrm{e}^{2 t}+p\left(1-(1-p) \mathrm{e}^t\right)^{-2} \mathrm{e}^t\end{aligned}$$

    带入得到$\mathbf{E}[X]=1 / p$, 以及$\mathbf{E}\left[X^2\right]=(2-p) / p^2$. 与我们先前计算的结果相符.
\end{example}


另一个有用的特性是, 随机变量的矩生成函数（或者说变量的所有矩）可以独特地描述其分布. 
不过, 证明太过复杂, 我们略去. 

\begin{theorem}
假设 $X$ 和 $Y$ 是两个随机变量. 如果存在一个 $\delta > 0$, 使得在区间 $(-\delta, \delta)$ 内对于所有 $t$ 都满足
$M_X(t) = M_Y(t)$, 那么 $X$ 和 $Y$ 将拥有相同的分布. 

\end{theorem}

上面的定理在确定独立随机变量之和的分布的时候非常有用. 

下面的一个性质是关于两个随机变量的矩的和的. 
\begin{theorem}
    如果 $X$ 和 $Y$ 是独立随机变量, 那么, $$M_{X+Y}(t)=M_X(t) M_Y(t).$$
\end{theorem}

\begin{proof}
    使用变量的独立性, 再使用幂的性质, 就得到了:$$M_{X+Y}(t)=\mathbf{E}\left[\mathrm{e}^{t(X+Y)}\right]=\mathbf{E}\left[\mathrm{e}^{t X} \mathrm{e}^{t Y}\right]=\mathbf{E}\left[\mathrm{e}^{t X}\right] \mathbf{E}\left[\mathrm{e}^{t Y}\right]=M_X(t) M_Y(t).$$
\end{proof}

\subsection{推导得到Chernoff界}

对于一个随机变量, 我们要想得到Chernoff界, 我们需要对于矩的生成函数$e^{tx}$选择一个比较好的$t$, 然后使用Markov不等式. 也就是, 对于任意的$t>0$, 有$$\operatorname{P}(X \geq a)=\operatorname{P}\left(\mathrm{e}^{t X} \geq \mathrm{e}^{t a}\right) \leq \frac{\mathbf{E}\left[\mathrm{e}^{t X}\right]}{\mathrm{e}^{t a}}$$我们取出所有$t>0$中使它最小的一个, 有$$
\operatorname{P}(X \geq a) \leq \min _{t>0} \frac{\mathbf{E}\left[\mathrm{e}^{t X}\right]}{\mathrm{e}^{t a}}.$$

同样的, 对于$t<0$, 有
$$
\operatorname{P}(X \leq a)=\operatorname{P}\left(\mathrm{e}^{t X} \geq \mathrm{e}^{t a}\right) \leq \frac{\mathbf{E}\left[\mathrm{e}^{t X}\right]}{\mathrm{e}^{t a}}
$$
因此
$$
\operatorname{P}(X \leq a) \leq \min _{t<0} \frac{\mathbf{E}\left[\mathrm{e}^{t X}\right]}{\mathrm{e}^{t a}}
$$

从这种方法导出的界叫做Chernoff界. 由于实际选取的$t$不一样, 我们得到的界的形式可能并不唯一. 

现在, 我们推导Chernoff界最常用的一种形式. 也就是若干个Poisson试验的和. 这些实验不一定同分布,  也就是令$X_1, X_2, \cdots, X_n$是一系列独立的Poisson实验, 也就是$\operatorname{P}\left(X_i=1\right)=p_i$. 令$X=\sum_{i=1}^n X_i$, 定义均值$\mu$为
$$
\mu=\mathbf{E}[X]=\mathbf{E}\left[\sum_{i=1}^n X_i\right]=\sum_{i=1}^n \mathbf{E}\left[X_i\right]=\sum_{i=1}^n p_i
$$
现在我们想关心 $X$ 偏离其期望的概率, 比如偏离$\delta \mu(\delta>0)$的概率是多少.  也就是看看$\operatorname{P}(X \geq(1+\delta) \mu)$以及$\operatorname{P}(X \leq(1-\delta) \mu)$的大小是多少.

要得到Chernoff界, 对于每一个$X_i$首先我们使用矩生成函数: 
$$
\begin{aligned}
M_{X_i}(t) & =\mathbf{E}\left[\mathrm{e}^{t X_i}\right] \\
& =p_i \mathrm{e}^t+\left(1-p_i\right) \\
& =1+p_i\left(\mathrm{e}^t-1\right) \\
& \leq \mathrm{e}^{p_i\left(\mathrm{e}^t-1\right)}, & (\text{使用不等式} 1+y\leq e^y)
\end{aligned}
$$

由于$n$个随机变量等于矩生成函数相乘, 以及每一个矩生成函数唯一决定了一个分布, 我们知道这些随机变量的和的矩的生成函数为: 

$$
\begin{aligned}
M_X(t) & =\prod_{i=1}^n M_{X_i}(t) \\
& \leq \prod_{i=1}^n \mathrm{e}^{p_i\left(\mathrm{e}^t-1\right)} \\
& =\exp \left\{\sum_{i=1}^n p_i\left(\mathrm{e}^t-1\right)\right\} \\
& =\mathrm{e}^{\left(\mathrm{e}^t-1\right) \mu} .
\end{aligned}
$$

有了这样的矩的生成函数, 我们就可以得到对应的Chernoff界. 
\begin{theorem}
    假设$X_1, X_2, \cdots, X_n$是互相独立的Poisson实验, 满足$\operatorname{P}\left(X_i=1\right)=p_i$. 令$X=\sum_{i=1}^n X_i$, 均值$\mu=\mathbf{E}[X]$, 有如下的Chernoff界: 
    \begin{itemize}
        \item 对于任意的$\delta>0$, $$\operatorname{P}(X \geq(1+\delta) \mu) \leq\left(\frac{\mathrm{e}^\delta}{(1+\delta)^{(1+\delta)}}\right)^\mu$$
        \item 对于任意的$0<\delta\leq 1$, $$
        \operatorname{P}(X \geq(1+\delta) \mu) \leq \mathrm{e}^{-\mu \delta^2 / 3}$$
        \item 对于$R\geq 6\mu$, $$
        \operatorname{P}(X \geq R) \leq 2^{-R}$$
    \end{itemize}
\end{theorem}

该定理的第一个界是最强的, 我们正是从这个界限推导出其他两个界限. 这些更加简单的界很多情况下容易叙述和计算. 

\begin{proof}
    使用Markov不等式, 对于任意的$t>0$, 我们有: 
    $$
\begin{aligned}
\operatorname{P}(X \geq(1+\delta) \mu) & =\operatorname{P}\left(\mathrm{e}^{t X} \geq \mathrm{e}^{t(1+\delta) \mu}\right) \\
& \leq \frac{\mathbf{E}\left[\mathrm{e}^{t X}\right]}{\mathrm{e}^{t(1+\delta) \mu}} \\
& \leq \frac{\mathrm{e}^{\left(\mathrm{e}^t-1\right) \mu}}{\mathrm{e}^{t(1+\delta) \mu}} .
\end{aligned}
$$
我们置$t=\ln(1+\delta)>0$得到
$$
\operatorname{P}(X \geq(1+\delta) \mu) \leq\left(\frac{\mathrm{e}^\delta}{(1+\delta)^{(1+\delta)}}\right)^\mu.
$$
也就是第一个等式. 要得到第二个等式, 我们需要说明, 对于$0<\delta\leq 1$, 有
$$
\frac{\mathrm{e}^\delta}{(1+\delta)^{(1+\delta)}} \leq \mathrm{e}^{-\delta^2 / 3}
$$
两边同时取对数, 就转化为普通高中生也会做的问题了. 具体地, 我们取$f(\delta)=\delta-(1+\delta) \ln (1+\delta)+\frac{\delta^2}{3} \leq 0$, 计算$f(\delta)$的导数, 
$$
\begin{aligned}
f^{\prime}(\delta) & =1-\frac{1+\delta}{1+\delta}-\ln (1+\delta)+\frac{2}{3} \delta \\
& =-\ln (1+\delta)+\frac{2}{3} \delta \\
f^{\prime \prime}(\delta) & =-\frac{1}{1+\delta}+\frac{2}{3} .
\end{aligned}
$$
我们看到对于 $0 \leq \delta < \frac{1}{2}$, 有 $f''(\delta) < 0$, 而对于 $\delta > \frac{1}{2}$, 有 $f''(\delta) > 0$. 因此在区间 $[0, 1]$ 上, $f'(\delta)$ 先减小后增加. 
考虑到 $f'(0) = 0$ 和 $f'(1) < 0$, 我们可以推断在区间 $[0, 1]$ 中 $f'(\delta) \leq 0$. 由于 $f(0) = 0$, 所以在该区间内 $f(\delta) \leq 0$. 
于是得到了第二个式子. 

对于第三个式子, 令$R=(1+\delta) \mu$, 那么, 对于$R\geq 6\mu$, $\delta=R / \mu-1 \geq 5$. 因此, 使用第一个式子, 有$$\begin{aligned} \operatorname{P}(X \geq(1+\delta) \mu) & \leq\left(\frac{\mathrm{e}^\delta}{(1+\delta)^{(1+\delta)}}\right)^\mu \\ & \leq\left(\frac{\mathrm{e}}{1+\delta}\right)^{(1+\delta) \mu} \\ & \leq\left(\frac{\mathrm{e}}{6}\right)^R \\ & \leq 2^{-R} .\end{aligned}$$
\end{proof}

上面探讨了高于平均值的概率. 其实对于低于平均值偏差为$\delta$的概率, 我们也有类似的结果: 
\begin{theorem}
    假设$X_1, X_2, \cdots, X_n$是互相独立的Poisson实验, 满足$\operatorname{P}\left(X_i=1\right)=p_i$. 令$X=\sum_{i=1}^n X_i$, 均值$\mu=\mathbf{E}[X]$, 对于$0<\delta<1$, 有
    \begin{itemize}
        \item $$\operatorname{P}(X \leq(1-\delta) \mu) \leq\left(\frac{\mathrm{e}^{-\delta}}{(1-\delta)^{(1-\delta)}}\right)^\mu$$
        \item $$\operatorname{P}(X \leq(1-\delta) \mu) \leq \mathrm{e}^{-\mu \delta^2 / 2}$$
    \end{itemize}
\end{theorem}

\begin{proof}
    对于$t<0$, 使用Markov不等式, 有
    $$
\begin{aligned}
\operatorname{P}(X \leq(1-\delta) \mu) & =\operatorname{P}\left(\mathrm{e}^{t X} \geq \mathrm{e}^{t(1-\delta) \mu}\right) \\
& \leq \frac{\mathbf{E}\left[\mathrm{e}^{t X}\right]}{\mathrm{e}^{t(1-\delta) \mu}} \\
& \leq \frac{\mathrm{e}^{\left(\mathrm{e}^t-1\right) \mu}}{\mathrm{e}^{t(1-\delta) \mu}} .
\end{aligned}
$$
对于$0<\delta<1$, 仿照上述, 设$t=\ln(1-\delta)$, 得到第一个式子
$$
\operatorname{P}(X \leq(1-\delta) \mu) \leq\left(\frac{\mathrm{e}^{-\delta}}{(1-\delta)^{(1-\delta)}}\right)^\mu
$$

仿照上述的证明该方法, 同样可以使用$\frac{\mathrm{e}^{-\delta}}{(1-\delta)^{(1-\delta)}} \leq \mathrm{e}^{-\delta^2 / 2}$成立, 证明第二个式子. 

\end{proof}

所以对于泊松分布而言, 距离均值的偏差到底是多少? 我们根据上面两个定理的第二个进行推论: 
\begin{corollary}
    假设$X_1, X_2, \cdots, X_n$是互相独立的Poisson实验, 满足$\operatorname{P}\left(X_i=1\right)=p_i$. 令$X=\sum_{i=1}^n X_i$, 均值$\mu=\mathbf{E}[X]$, 对于$0<\delta<1$, 有
    $$\operatorname{P}(|X-\mu| \geq \delta \mu) \leq 2 \mathrm{e}^{-\mu \delta^2 / 3}.$$
\end{corollary}

\begin{example}[投硬币]
    令随机变量$X$表示$n$次独立的投掷中, 正面向上的次数. 使用Chernoff界, 我们得到
    $$\begin{aligned} \operatorname{P}\left(\left|X-\frac{n}{2}\right| \geq \frac{1}{2} \sqrt{6 n \ln n}\right) & \leq 2 \exp \left\{-\frac{1}{3} \frac{n}{2} \frac{6 \ln n}{n}\right\} \\ & =\frac{2}{n}\end{aligned}$$

    这表示均值聚集在$n/2$的过程是十分快速的. 大多数时候, 与平均值的偏差约为$O(\sqrt{n\ln n})$.

    考虑我们想要一个序列中不多于$n/4$个正面, 不少于$3n/4$个反面, 使用Chebyshev不等式, 得到$\operatorname{P}\left(\left|X-\frac{n}{2}\right| \geq \frac{n}{4}\right) \leq \frac{4}{n}$. 而使用刚刚的Chernoff界我们就发现随着$n$增大, 我们实际上在指数衰减. 也就是
    $$
\begin{aligned}
\operatorname{P}\left(\left|X-\frac{n}{2}\right| \geq \frac{n}{4}\right) & \leq 2 \exp \left\{-\frac{1}{3} \frac{n}{2} \frac{1}{4}\right\} \\
& \leq 2 \mathrm{e}^{-n / 24} .
\end{aligned}
$$
因此, Chernoff界给出的结果比使用Chebyshev不等式获得的界要小得多. 
    
\end{example}

\subsection{Hoeffding界}

如果我们的随机变量是有界的, 那么可以使用Hoeffding界来获得更加紧的界. 我们先来陈述这一事实. 

\begin{theorem}[Hoeffding界]
    令$X_1, X_2, \cdots, X_n$是互相独立的随机变量, 并且对于任意的$1\leq i\leq n, \Ep{X_i}=\mu, P(a\leq X_i \leq b)=1$, 那么
    $$
\operatorname{P}\left(\left|\frac{1}{n} \sum_{i=1}^n X_i-\mu\right| \geq \epsilon\right) \leq 2 \mathrm{e}^{-2 n \epsilon^2 /(b-a)^2}
$$
\end{theorem}

要证明这个定理, 首先需要证明一个引理. 
\begin{lemma}
    设$X$是一个随机变量, $\operatorname{P}(X \in[a, b])=1$ 并且 $\mathbf{E}[X]=0$. 那么对于任意的 $\lambda>0$,有
    $$
\mathbf{E}\left[\mathrm{e}^{\lambda X}\right] \leq \mathrm{e}^{\lambda^2(b-a)^2 / 8} .
$$
\end{lemma}

\begin{proof}
    由于$f(x)=\mathrm{e}^{\lambda x}$是一个凸函数, 对任意$\alpha \in(0,1)$有
    $$
f(\alpha a+(1-\alpha) b) \leq \alpha \mathrm{e}^{\lambda a}+(1-\alpha) \mathrm{e}^{\lambda b}
$$
对于$x\in [a, b]$, 令$\alpha=\frac{b-x}{b-a}$, 这样一来, $x=\alpha a+(1-\alpha) b$. 我们就有
$$
\mathrm{e}^{\lambda x} \leq \frac{b-x}{b-a} \mathrm{e}^{\lambda a}+\frac{x-a}{b-a} \mathrm{e}^{\lambda b}
$$
考虑取$\mathrm{e}^{\lambda X}$的期望, 由于$\Ep{X}=0$, 我们有
$$
\begin{aligned}
\mathbf{E}\left[\mathrm{e}^{\lambda X}\right] & \leq \mathbf{E}\left[\frac{b-X}{b-a} \mathrm{e}^{\lambda a}\right]+\mathbf{E}\left[\frac{X-a}{b-a} \mathrm{e}^{\lambda b}\right] \\
& =\frac{b}{b-a} \mathrm{e}^{\lambda a}-\frac{\mathbf{E}[X]}{b-a} \mathrm{e}^{\lambda a}-\frac{a}{b-a} \mathrm{e}^{\lambda b}+\frac{\mathbf{E}[X]}{b-a} \mathrm{e}^{\lambda b} \\
& =\frac{b}{b-a} \mathrm{e}^{\lambda a}-\frac{a}{b-a} \mathrm{e}^{\lambda b}
\end{aligned}
$$
下面对于最终的表达式做一点操作. 令$\phi(t)=-\theta t+$ $\ln \left(1-\theta+\theta \mathrm{e}^t\right)$, 对于 $\theta=\frac{-a}{b-a}>0$. 有
$$
\begin{aligned}
\mathrm{e}^{\phi(\lambda(b-a))} & =\mathrm{e}^{-\theta \lambda(b-a)}\left(1-\theta+\theta \mathrm{e}^{\lambda(b-a)}\right) \\
& =\mathrm{e}^{\lambda a}\left(1-\theta+\theta \mathrm{e}^{\lambda(b-a)}\right) \\
& =\mathrm{e}^{\lambda a}\left(\frac{b}{b-a}-\frac{a}{b-a} \mathrm{e}^{\lambda(b-a)}\right) \\
& =\frac{b}{b-a} \mathrm{e}^{\lambda a}-\frac{a}{b-a} \mathrm{e}^{\lambda b},
\end{aligned}
$$
这和我们推出的上界$\Ep{\exp(\lambda X)}$相等. 我们发现$\varphi(0)=\varphi'(0)=0,$对于任意的$t, \varphi''(t)\leq 1/4$. 根据 Taylor 展开, 对于任意的$t>0$, 都有$t'$使得$t'\in [0,t]$, 
$$
\phi(t)=\phi(0)+t \phi^{\prime}(0)+\frac{1}{2} t^2 \phi^{\prime \prime}\left(t^{\prime}\right) \leq \frac{1}{8} t^2
$$
因此, 对于$t=\lambda (b-a)$, 有
$$
\phi(\lambda(b-a)) \leq \frac{\lambda^2(b-a)^2}{8}
$$
于是
$$
\mathbf{E}\left[\mathrm{e}^{\lambda X}\right] \leq \mathrm{e}^{\phi(\lambda(b-a))} \leq \mathrm{e}^{\lambda^2(b-a)^2 / 8}
$$
\end{proof}

有了这个引理, 我们下面证明Hoeffding界. 

\begin{proof}
    令$Z_i=X_i-\mathbf{E}\left[X_i\right]$, $Z=\frac 1 n \sum_{i=1}^n Z_i.$

    对于任意的$\lambda>0$, 根据Markov不等式, 
    $$
    \begin{aligned}
    \operatorname{P}(Z \geq \epsilon) & =\operatorname{P}\left(\mathrm{e}^{\lambda Z} \geq \mathrm{e}^{\lambda \epsilon}\right) \leq \mathrm{e}^{-\lambda \epsilon} \mathbf{E}\left[\mathrm{e}^{\lambda Z}\right] \leq \mathrm{e}^{-\lambda \epsilon} \prod_{i=1}^n \mathbf{E}\left[\mathrm{e}^{\lambda Z_i / n}\right] \\
    & \leq \mathrm{e}^{-\lambda \epsilon} \prod_{i=1}^n \mathrm{e}^{\lambda^2(b-a)^2 / n^2} \leq \mathrm{e}^{-\lambda \epsilon+\lambda^2(b-a)^2 / 8 n}
    \end{aligned}
    $$

    在倒数第二个步骤中，我们运用了上述引理，并利用了 $Z_i/n$ 被限制在 $\frac{a - \mu}{n}$ 和 $\frac{b - \mu}{n}$ 之间这一事实。设置$\lambda=\frac{4 n \epsilon}{(b-a)^2}$得到: 
    $$
\operatorname{P}\left(\frac{1}{n} \sum_{i=1}^n X_i-\mu \geq \epsilon\right)=\operatorname{P}(Z \geq \epsilon) \leq \mathrm{e}^{-2 n \epsilon^2 /(b-a)^2}
$$
对于$Z\leq -\epsilon$的情况, 有同样的情况. 因此定理得证. 

\end{proof}

\end{document}


